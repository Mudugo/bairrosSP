import requests
from bs4 import BeautifulSoup
import pandas as pd

# Função para obter o conteúdo de uma página
def obter_bairros(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    # Encontrar todos os itens da lista de bairros
    bairros = soup.find('ul', {'id': 'activity-stream'}).find_all('li')

    # Lista para armazenar dados dos bairros
    dados_bairros = []

    # Extrair os detalhes de cada bairro
    for bairro in bairros:
        nome_bairro = bairro.find('span', {'class': 'title-list'}).text.strip()
        detalhes_bairro = bairro.find('p').get_text(separator=' ').strip()
        
        # Adicionando os dados do bairro na lista
        dados_bairros.append([nome_bairro, detalhes_bairro])
    
    return dados_bairros

# Lista geral para armazenar todos os bairros de todas as páginas
todos_os_bairros = []

# Loop para acessar todas as páginas de 1 a 152
for i in range(1, 153):
    url = f'https://www.saopauloguiafacil.com.br/bairros/{i}'
    print(f'Acessando página {i}...')
    bairros_pagina = obter_bairros(url)
    todos_os_bairros.extend(bairros_pagina)

# Criar DataFrame com os dados coletados
df_bairros = pd.DataFrame(todos_os_bairros, columns=['Bairro', 'Detalhes'])

# Salvar em um arquivo Excel
df_bairros.to_excel('bairros_sao_paulo.xlsx', index=False)

print("Dados salvos em bairros_sao_paulo.xlsx")
